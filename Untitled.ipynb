{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "from sklearn import ensemble, naive_bayes, tree\n",
    "\n",
    "\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduced_data = pd.read_excel('./output/reduced_data.xlsx')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reduced_data.drop(config.TARGET, axis=1), \n",
    "    reduced_data[config.TARGET], \n",
    "    test_size=0.20, \n",
    "    stratify=reduced_data[config.TARGET], \n",
    "    random_state=config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "from config import config\n",
    "\n",
    "def BaseLineModels(models, X, y):\n",
    "    \n",
    "    row_index = 0\n",
    "    cv_split = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 42)\n",
    "    baseline_output = pd.DataFrame(columns=['model', 'mean_train_acc', 'mean_test_acc', 'parameters'])\n",
    "    \n",
    "    for model in [models[key]['model'] for key in models]:\n",
    "        baseline_output.loc[row_index, 'model'] = model.__class__.__name__\n",
    "        cross_validation_result = cross_validate(model, X, y, cv = cv_split, return_train_score=True, scoring='f1')\n",
    "        model_parameters = model.fit(X, y).get_params()\n",
    "        \n",
    "        baseline_output.loc[row_index, 'mean_train_acc'] = cross_validation_result['train_score'].mean()\n",
    "        baseline_output.loc[row_index, 'mean_test_acc'] = cross_validation_result['test_score'].mean()\n",
    "        baseline_output.loc[row_index, 'parameters'] = [model_parameters]\n",
    "        row_index+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "    baseline_output.sort_values(by='mean_test_acc', ascending=False, inplace=True)\n",
    "    \n",
    "    row_index = 0\n",
    "    tuned_output = pd.DataFrame(columns=['model', 'mean_train_acc_tuned', 'mean_test_acc_tuned', 'parameters_tuned'])\n",
    "    \n",
    "    for model in [models[key] for key in models]:\n",
    "        tuned_output.loc[row_index, 'model'] = model['model'].__class__.__name__\n",
    "        tuned_model = RandomizedSearchCV(model['model'], param_distributions=model['param_grid'], scoring = 'f1', cv = cv_split, return_train_score=True)\n",
    "        tuned_model.fit(X, y)\n",
    "\n",
    "        tuned_output.loc[row_index, 'mean_train_acc_tuned'] = tuned_model.cv_results_['mean_train_score'][tuned_model.best_index_]\n",
    "        tuned_output.loc[row_index, 'mean_test_acc_tuned'] = tuned_model.cv_results_['mean_test_score'][tuned_model.best_index_]\n",
    "        tuned_output.loc[row_index, 'parameters_tuned'] = [tuned_model.best_params_]\n",
    "        row_index+=1\n",
    "\n",
    "    \n",
    "\n",
    "    output = baseline_output.join(tuned_output.set_index('model'), on='model')\n",
    "    output.sort_values(by='mean_test_acc_tuned', ascending=False, inplace=True)\n",
    "    \n",
    "    return output #baseline_output, tuned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1787, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1787, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1787, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1787, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Calle\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "output = BaseLineModels(config.MODELS, scaler.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_test_acc</th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean_train_acc_tuned</th>\n",
       "      <th>mean_test_acc_tuned</th>\n",
       "      <th>parameters_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.579227</td>\n",
       "      <td>0.566728</td>\n",
       "      <td>[{'Cs': 10, 'class_weight': None, 'cv': None, ...</td>\n",
       "      <td>0.660454</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>[{'random_state': 42, 'penalty': 'l2', 'max_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.630829</td>\n",
       "      <td>0.627016</td>\n",
       "      <td>[{'priors': None, 'var_smoothing': 1e-09}]</td>\n",
       "      <td>0.630829</td>\n",
       "      <td>0.627016</td>\n",
       "      <td>[{}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.995055</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>[{'bootstrap': True, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.697248</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>[{'random_state': 42, 'n_estimators': 30, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.603541</td>\n",
       "      <td>0.609561</td>\n",
       "      <td>[{'alpha': 1.0, 'binarize': 0.0, 'class_prior'...</td>\n",
       "      <td>0.603541</td>\n",
       "      <td>0.609561</td>\n",
       "      <td>[{}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.667769</td>\n",
       "      <td>0.605457</td>\n",
       "      <td>[{'algorithm': 'SAMME.R', 'base_estimator': No...</td>\n",
       "      <td>0.667769</td>\n",
       "      <td>0.605457</td>\n",
       "      <td>[{'base_estimator': None}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>0.535068</td>\n",
       "      <td>[{'ccp_alpha': 0.0, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.655849</td>\n",
       "      <td>0.575803</td>\n",
       "      <td>[{'splitter': 'random', 'random_state': 42, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.559939</td>\n",
       "      <td>[{'algorithm': 'auto', 'leaf_size': 30, 'metri...</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>0.561724</td>\n",
       "      <td>[{'weights': 'distance', 'p': 1, 'n_neighbors'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model mean_train_acc mean_test_acc  \\\n",
       "1    LogisticRegressionCV       0.579227      0.566728   \n",
       "3              GaussianNB       0.630829      0.627016   \n",
       "6  RandomForestClassifier       0.995055      0.602756   \n",
       "2             BernoulliNB       0.603541      0.609561   \n",
       "5      AdaBoostClassifier       0.667769      0.605457   \n",
       "4  DecisionTreeClassifier       0.995132      0.535068   \n",
       "0    KNeighborsClassifier       0.701791      0.559939   \n",
       "\n",
       "                                          parameters mean_train_acc_tuned  \\\n",
       "1  [{'Cs': 10, 'class_weight': None, 'cv': None, ...             0.660454   \n",
       "3         [{'priors': None, 'var_smoothing': 1e-09}]             0.630829   \n",
       "6  [{'bootstrap': True, 'ccp_alpha': 0.0, 'class_...             0.697248   \n",
       "2  [{'alpha': 1.0, 'binarize': 0.0, 'class_prior'...             0.603541   \n",
       "5  [{'algorithm': 'SAMME.R', 'base_estimator': No...             0.667769   \n",
       "4  [{'ccp_alpha': 0.0, 'class_weight': None, 'cri...             0.655849   \n",
       "0  [{'algorithm': 'auto', 'leaf_size': 30, 'metri...             0.995132   \n",
       "\n",
       "  mean_test_acc_tuned                                   parameters_tuned  \n",
       "1            0.664652  [{'random_state': 42, 'penalty': 'l2', 'max_it...  \n",
       "3            0.627016                                               [{}]  \n",
       "6            0.619469  [{'random_state': 42, 'n_estimators': 30, 'min...  \n",
       "2            0.609561                                               [{}]  \n",
       "5            0.605457                         [{'base_estimator': None}]  \n",
       "4            0.575803  [{'splitter': 'random', 'random_state': 42, 'm...  \n",
       "0            0.561724  [{'weights': 'distance', 'p': 1, 'n_neighbors'...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = baseline_output.join(tuned_output.set_index('model'), on='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sort_values(by='mean_test_acc_tuned', ascending=False, inplace=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 42)\n",
    "row_index = 0\n",
    "tuned_output = pd.DataFrame(columns=['model', 'mean_train_acc_tuned', 'mean_test_acc_tuned', 'parameters_tuned'])\n",
    "\n",
    "for model in [config.MODELS[key] for key in config.MODELS]:\n",
    "    print(model['model'])\n",
    "    tuned_output.loc[row_index, 'model'] = model['model'].__class__.__name__\n",
    "    #if len(config.MODELS[model]['param_grid'])!=0:\n",
    "    print('randomized search')\n",
    "    tuned_model = RandomizedSearchCV(model['model'], param_distributions=model['param_grid'], scoring = 'f1', cv = cv_split, return_train_score=True)\n",
    "    print('fitting model')\n",
    "    print(tuned_model.fit(scaler.fit_transform(X_train), y_train))\n",
    "    tuned_model.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "    #tuned_output.loc[row_index, 'mean_train_acc_tuned'] = tuned_model.cv_results_['mean_train_score'][tuned_model.best_index_]\n",
    "    #tuned_output.loc[row_index, 'mean_test_acc_tuned'] = tuned_model.cv_results_['mean_test_score'][tuned_model.best_index_]\n",
    "    #tuned_output.loc[row_index, 'parameters_tuned'] = [tuned_model.best_params_]\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.arange(-4., 6.):\n",
    "...     lr = LogisticRegression(penalty='l1', C=10.**c,\n",
    "...                             solver='liblinear',\n",
    "...                             multi_class='ovr', random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.001\n",
      "0.01\n",
      "0.1\n",
      "1.0\n",
      "10.0\n",
      "100.0\n",
      "1000.0\n",
      "10000.0\n",
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "for c in np.arange(-4., 6.):\n",
    "    print(10.**c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(10**np.arange(-4., 6.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 10, 100, 1000, 10000, 100000]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (<ipython-input-16-1e4123b2391f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-1e4123b2391f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    'LogisticRegression': {\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'param_grid': {\n",
    "            'penalty': ['l2'],\n",
    "            'C': [int(val) for val in list(10**np.arange(-4., 6.))],\n",
    "            'class_weight': [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "            'solver': [ 'newton-cg', 'sag', 'lbfgs'],\n",
    "            'max_iter': [1000],\n",
    "            'random_state': [RANDOM_STATE]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " params =   {\n",
    "            'penalty': ['l2'],\n",
    "            'C': list(10.**np.arange(-4., 6.)),\n",
    "            'class_weight': [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "            'solver': ['lbfgs'],\n",
    "            'max_iter': [1000],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "\n",
    "ape = RandomizedSearchCV(LogisticRegression(), \n",
    "                         param_distributions=params, \n",
    "                         scoring = 'f1', \n",
    "                         cv = cv_split, \n",
    "                         return_train_score=True)\n",
    "\n",
    "goat = ape.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'newton-cg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(10.**np.arange(-4., 6.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.3, train_size=0.7),\n",
       "                   estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                                              10.0, 100.0, 1000.0, 10000.0,\n",
       "                                              100000.0],\n",
       "                                        'class_weight': [{0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.3, 1: 0.7}],\n",
       "                                        'max_iter': [1000], 'penalty': ['l2'],\n",
       "                                        'random_state': [42],\n",
       "                                        'solver': ['lbfgs']},\n",
       "                   return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
